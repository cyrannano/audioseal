{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import scipy.signal\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import typing as tp\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import soundfile as sf\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata and audio samples from CREMA-D dataset\n",
    "def load_crema_d_metadata(metadata_path):\n",
    "    df = pd.read_csv(metadata_path)\n",
    "    return df\n",
    "\n",
    "def load_audio_samples(actor_id, base_path):\n",
    "    file_paths = []\n",
    "    # find all audio files starting with the actor_id\n",
    "    for file_path in glob.glob(f\"{base_path}/{actor_id}*.wav\"):\n",
    "        file_paths.append(file_path)\n",
    "    \n",
    "    audio_samples = []\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        audio, sr = load_audio_sample(file_path)\n",
    "        audio_samples.append((audio, sr, file_path))\n",
    "    \n",
    "    return audio_samples\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def load_audio_sample(\n",
    "    file_path: str\n",
    ") -> tp.Optional[tp.Tuple[torch.Tensor, int]]:\n",
    "    try:\n",
    "        wav, sample_rate = torchaudio.load(file_path)\n",
    "        return wav, sample_rate\n",
    "    except Exception as e:\n",
    "        print(f\"Error while loading audio: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resample_audio(audio, original_sr, target_sr):\n",
    "    return librosa.resample(audio, orig_sr=original_sr, target_sr=target_sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import os\n",
    "\n",
    "metadata_path = '../crema-d/VideoDemographics.csv'  # Placeholder path\n",
    "base_audio_path = '../crema-d'  # Placeholder path\n",
    "\n",
    "crema_d_metadata = load_crema_d_metadata(metadata_path)\n",
    "crema_d_metadata = random.choice(crema_d_metadata['ActorID'].values)\n",
    "\n",
    "output_dir = 'random-test-output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# delete all files in the output directory\n",
    "for file in glob.glob(f\"{output_dir}/*\"):\n",
    "    os.remove(file)\n",
    "\n",
    "audio_sr = load_audio_samples(crema_d_metadata, base_audio_path)\n",
    "for audio, sr, fp in random.sample(audio_sr, 1):\n",
    "    audio = resample_audio(audio.numpy().flatten(), sr, sr*2)\n",
    "    sf.write(f'{output_dir}/{os.path.basename(fp)}', audio, sr * 2)\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
